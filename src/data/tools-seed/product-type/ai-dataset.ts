// üìä Popular AI Datasets
export const aiDatasetList = [
  // üî§ NLP Datasets
  'Common Crawl', // Massive web text corpus
  'C4 (Colossal Clean Crawled Corpus)', // Used in T5/PaLM
  'The Pile', // Curated text dataset for LLMs
  'BooksCorpus', // Book texts (used in GPT, BERT)
  'Wikipedia Dump', // General-purpose knowledge
  'OpenWebText', // Open-source replacement for WebText
  'Wikitext-103', // Clean Wikipedia text
  'RedPajama', // Open LLM training dataset
  'Project Gutenberg', // Public domain books
  'Stack Exchange Data Dump', // Q&A data

  // üñºÔ∏è Computer Vision Datasets
  'ImageNet', // Benchmark for image classification
  'COCO (Common Objects in Context)', // Object detection & segmentation
  'Open Images Dataset', // Google‚Äôs large-scale dataset
  'CIFAR-10', // Classic image dataset
  'CIFAR-100', // Fine-grained classification
  'Places365', // Scene recognition dataset
  'Visual Genome', // Image + relationship annotations
  'Tiny ImageNet', // Scaled-down ImageNet
  'CelebA', // Celebrity faces dataset
  'MNIST', // Handwritten digits dataset
  'Fashion-MNIST', // Clothing classification
  'SVHN (Street View House Numbers)', // Digit recognition from street images
  'Kinetics-700', // Human action video dataset

  // üó£Ô∏è Speech & Audio Datasets
  'LibriSpeech', // Audiobooks for ASR
  'VoxCeleb', // Speaker recognition dataset
  'Common Voice (Mozilla)', // Open-source multilingual speech dataset
  'TED-LIUM', // TED talks for ASR
  'AMI Meeting Corpus', // Meeting recordings
  'AudioSet', // Google‚Äôs audio event dataset
  'ESC-50', // Environmental sounds dataset
  'UrbanSound8K', // Urban environment sounds

  // üß† Multimodal Datasets
  'LAION-400M', // Image-text pairs
  'LAION-5B', // Large-scale web dataset
  'Conceptual Captions', // Image-text dataset
  'Flickr30k', // Images + captions
  'MSR-VTT', // Video + captions
  'HowTo100M', // Instructional video dataset
  'WebVid-10M', // Video-text dataset
  'VQAv2 (Visual Question Answering)', // Images + Q&A pairs
  'TextCaps', // Image captioning dataset
  'CLIP Benchmark Dataset', // Image-text for contrastive learning

  // üß¨ Specialized Datasets
  'PubMed', // Biomedical papers
  'MedQA', // Medical question-answering
  'MIMIC-III', // Clinical health records
  'CheXpert', // Chest X-rays dataset
  'KITTI', // Self-driving dataset
  'Waymo Open Dataset', // Autonomous driving
  'NuScenes', // Self-driving scenes
  'ArXiv Dataset', // Scientific papers
  'SQuAD (Stanford QA Dataset)', // QA dataset
  'Natural Questions (Google)', // QA dataset
  'TriviaQA', // Open-domain QA
];
